#!/usr/bin/env python3
"""
ê°œë°œì í”„ë¡œí•„ ë¶„ì„ê¸°
~/.claude/projects/ ë””ë ‰í† ë¦¬ì˜ ëŒ€í™” ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬ ê°œë°œì í”„ë¡œí•„ì„ ìƒì„±í•©ë‹ˆë‹¤.
"""

import json
import os
import re
from collections import Counter, defaultdict
from datetime import datetime
from pathlib import Path
from typing import Any

# ì‹œê°í™”ëŠ” ì„ íƒì  ì˜ì¡´ì„±
try:
    import matplotlib.pyplot as plt
    import matplotlib.font_manager as fm
    HAS_MATPLOTLIB = True
except ImportError:
    HAS_MATPLOTLIB = False

CLAUDE_PROJECTS_DIR = Path.home() / ".claude" / "projects"

# ê¸°ìˆ  ìŠ¤íƒ í‚¤ì›Œë“œ ë§¤í•‘
TECH_KEYWORDS = {
    "languages": {
        "python": ["python", ".py", "pip", "pytest", "django", "flask", "fastapi"],
        "typescript": ["typescript", ".ts", ".tsx", "tsc"],
        "javascript": ["javascript", ".js", ".jsx", "node", "npm", "yarn"],
        "rust": ["rust", ".rs", "cargo", "rustc"],
        "go": ["golang", ".go", "go build", "go run"],
        "java": ["java", ".java", "maven", "gradle", "spring"],
        "kotlin": [".kt", "kotlin"],
        "swift": [".swift", "swiftui", "xcode"],
        "c++": [".cpp", ".hpp", "cmake"],
        "c#": [".cs", "dotnet", "csharp"],
    },
    "frameworks": {
        "react": ["react", "jsx", "tsx", "next.js", "nextjs"],
        "vue": ["vue", "vuex", "nuxt"],
        "angular": ["angular", "ng "],
        "express": ["express", "expressjs"],
        "fastapi": ["fastapi"],
        "django": ["django"],
        "flask": ["flask"],
        "spring": ["spring", "springboot"],
    },
    "tools": {
        "git": ["git ", "commit", "push", "pull", "branch", "merge"],
        "docker": ["docker", "dockerfile", "container"],
        "kubernetes": ["kubernetes", "k8s", "kubectl", "helm"],
        "aws": ["aws", "s3", "ec2", "lambda", "cloudformation"],
        "terraform": ["terraform", ".tf"],
        "github_actions": ["github actions", ".github/workflows"],
    },
    "databases": {
        "postgresql": ["postgres", "postgresql", "psql"],
        "mysql": ["mysql", "mariadb"],
        "mongodb": ["mongodb", "mongo"],
        "redis": ["redis"],
        "sqlite": ["sqlite"],
    },
}

# ì‘ì—… ìœ í˜• í‚¤ì›Œë“œ
TASK_PATTERNS = {
    "debugging": ["fix", "bug", "error", "issue", "broken", "not working", "debug", "ì™œ ì•ˆ", "ì—ëŸ¬", "ë²„ê·¸"],
    "new_feature": ["add", "create", "implement", "new", "build", "ë§Œë“¤ì–´", "ì¶”ê°€", "êµ¬í˜„"],
    "refactoring": ["refactor", "clean", "improve", "optimize", "ë¦¬íŒ©í† ë§", "ê°œì„ ", "ì •ë¦¬"],
    "learning": ["how to", "what is", "explain", "ì–´ë–»ê²Œ", "ë­ì•¼", "ì„¤ëª…", "ì•Œë ¤ì¤˜"],
    "review": ["review", "check", "look at", "ë¦¬ë·°", "í™•ì¸", "ê²€í† "],
    "testing": ["test", "spec", "í…ŒìŠ¤íŠ¸", "ê²€ì¦"],
    "documentation": ["document", "readme", "comment", "ë¬¸ì„œ", "ì£¼ì„"],
}


def load_sessions_index(project_dir: Path) -> list[dict]:
    """ì„¸ì…˜ ì¸ë±ìŠ¤ íŒŒì¼ ë¡œë“œ"""
    index_file = project_dir / "sessions-index.json"
    if not index_file.exists():
        return []

    with open(index_file) as f:
        data = json.load(f)
        return data.get("entries", [])


def load_session_messages(jsonl_path: Path) -> list[dict]:
    """JSONL íŒŒì¼ì—ì„œ ë©”ì‹œì§€ ë¡œë“œ"""
    messages = []
    if not jsonl_path.exists():
        return messages

    with open(jsonl_path) as f:
        for line in f:
            try:
                entry = json.loads(line.strip())
                if entry.get("type") in ["user", "assistant"]:
                    messages.append(entry)
            except json.JSONDecodeError:
                continue

    return messages


def extract_user_messages(messages: list[dict]) -> list[str]:
    """ì‚¬ìš©ì ë©”ì‹œì§€ë§Œ ì¶”ì¶œ"""
    user_texts = []
    for msg in messages:
        if msg.get("type") == "user":
            content = msg.get("message", {}).get("content", "")
            if isinstance(content, str):
                user_texts.append(content)
            elif isinstance(content, list):
                for item in content:
                    if isinstance(item, dict) and item.get("type") == "text":
                        user_texts.append(item.get("text", ""))
    return user_texts


def extract_file_changes(messages: list[dict]) -> list[str]:
    """íŒŒì¼ ë³€ê²½ ë‚´ì—­ ì¶”ì¶œ"""
    files = []
    for msg in messages:
        if msg.get("type") == "file-history-snapshot":
            snapshot = msg.get("snapshot", {})
            tracked = snapshot.get("trackedFileBackups", {})
            files.extend(tracked.keys())
    return files


def analyze_tech_stack(texts: list[str], files: list[str]) -> dict[str, Counter]:
    """ê¸°ìˆ  ìŠ¤íƒ ë¶„ì„"""
    combined_text = " ".join(texts + files).lower()

    results = {}
    for category, techs in TECH_KEYWORDS.items():
        counter = Counter()
        for tech, keywords in techs.items():
            count = sum(1 for kw in keywords if kw.lower() in combined_text)
            if count > 0:
                counter[tech] = count
        results[category] = counter

    return results


def analyze_task_types(texts: list[str]) -> Counter:
    """ì‘ì—… ìœ í˜• ë¶„ì„"""
    combined_text = " ".join(texts).lower()
    counter = Counter()

    for task_type, patterns in TASK_PATTERNS.items():
        count = sum(1 for p in patterns if p.lower() in combined_text)
        if count > 0:
            counter[task_type] = count

    return counter


def analyze_working_hours(sessions: list[dict]) -> dict:
    """ì‘ì—… ì‹œê°„ëŒ€ ë¶„ì„"""
    hours = Counter()
    weekdays = Counter()

    for session in sessions:
        created = session.get("created")
        if created:
            try:
                dt = datetime.fromisoformat(created.replace("Z", "+00:00"))
                hours[dt.hour] += 1
                weekdays[dt.strftime("%A")] += 1
            except:
                continue

    return {"hours": hours, "weekdays": weekdays}


def calculate_metrics(sessions: list[dict], all_user_messages: list[str]) -> dict:
    """ì£¼ìš” ë©”íŠ¸ë¦­ ê³„ì‚°"""
    total_sessions = len(sessions)
    total_messages = sum(s.get("messageCount", 0) for s in sessions)

    # í‰ê·  ë©”ì‹œì§€ ê¸¸ì´
    avg_message_length = (
        sum(len(m) for m in all_user_messages) / len(all_user_messages)
        if all_user_messages else 0
    )

    # ì§ˆë¬¸í˜• ë©”ì‹œì§€ ë¹„ìœ¨
    question_count = sum(1 for m in all_user_messages if "?" in m or "?" in m)
    question_ratio = question_count / len(all_user_messages) if all_user_messages else 0

    return {
        "total_sessions": total_sessions,
        "total_messages": total_messages,
        "avg_messages_per_session": total_messages / total_sessions if total_sessions else 0,
        "avg_message_length": round(avg_message_length),
        "question_ratio": round(question_ratio * 100, 1),
    }


def generate_profile(anonymize: bool = True) -> dict[str, Any]:
    """ê°œë°œì í”„ë¡œí•„ ìƒì„±"""
    all_sessions = []
    all_user_messages = []
    all_files = []
    project_names = []

    # ëª¨ë“  í”„ë¡œì íŠ¸ ìˆœíšŒ
    for project_dir in CLAUDE_PROJECTS_DIR.iterdir():
        if not project_dir.is_dir():
            continue

        sessions = load_sessions_index(project_dir)
        all_sessions.extend(sessions)

        # í”„ë¡œì íŠ¸ ì´ë¦„ ì¶”ì¶œ (ìµëª…í™” ì‹œ í•´ì‹œ)
        project_name = project_dir.name
        if anonymize:
            project_name = f"project_{hash(project_name) % 10000:04d}"
        project_names.append(project_name)

        # ì„¸ì…˜ë³„ ë©”ì‹œì§€ ë¡œë“œ
        for session in sessions:
            jsonl_path = Path(session.get("fullPath", ""))
            messages = load_session_messages(jsonl_path)
            all_user_messages.extend(extract_user_messages(messages))
            all_files.extend(extract_file_changes(messages))

    # ë¶„ì„ ì‹¤í–‰
    tech_stack = analyze_tech_stack(all_user_messages, all_files)
    task_types = analyze_task_types(all_user_messages)
    working_hours = analyze_working_hours(all_sessions)
    metrics = calculate_metrics(all_sessions, all_user_messages)

    # í”„ë¡œí•„ ìƒì„±
    profile = {
        "generated_at": datetime.now().isoformat(),
        "anonymized": anonymize,
        "metrics": metrics,
        "tech_stack": {
            category: dict(counter.most_common(5))
            for category, counter in tech_stack.items()
            if counter
        },
        "task_types": dict(task_types.most_common()),
        "working_patterns": {
            "peak_hours": [h for h, _ in working_hours["hours"].most_common(3)],
            "active_days": [d for d, _ in working_hours["weekdays"].most_common(3)],
        },
        "hours_detail": dict(working_hours["hours"]),
        "weekdays_detail": dict(working_hours["weekdays"]),
        "project_count": len(set(project_names)),
    }

    return profile


def generate_summary(profile: dict) -> str:
    """í”„ë¡œí•„ ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„±"""
    lines = ["## ê°œë°œì í”„ë¡œí•„ ë¶„ì„ ê²°ê³¼\n"]

    # ë©”íŠ¸ë¦­
    m = profile["metrics"]
    lines.append(f"### í™œë™ í†µê³„")
    lines.append(f"- ì´ ì„¸ì…˜ ìˆ˜: {m['total_sessions']}")
    lines.append(f"- ì´ ë©”ì‹œì§€ ìˆ˜: {m['total_messages']}")
    lines.append(f"- ì„¸ì…˜ë‹¹ í‰ê·  ë©”ì‹œì§€: {m['avg_messages_per_session']:.1f}")
    lines.append(f"- í‰ê·  ë©”ì‹œì§€ ê¸¸ì´: {m['avg_message_length']} ì")
    lines.append(f"- ì§ˆë¬¸í˜• ë©”ì‹œì§€ ë¹„ìœ¨: {m['question_ratio']}%")
    lines.append(f"- í”„ë¡œì íŠ¸ ìˆ˜: {profile['project_count']}\n")

    # ê¸°ìˆ  ìŠ¤íƒ
    if profile["tech_stack"]:
        lines.append("### ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒ")
        for category, techs in profile["tech_stack"].items():
            if techs:
                tech_list = ", ".join(f"{t}({c})" for t, c in techs.items())
                lines.append(f"- **{category}**: {tech_list}")
        lines.append("")

    # ì‘ì—… ìœ í˜•
    if profile["task_types"]:
        lines.append("### ì‘ì—… ìœ í˜• ë¶„í¬")
        for task, count in profile["task_types"].items():
            lines.append(f"- {task}: {count}")
        lines.append("")

    # ì‘ì—… íŒ¨í„´
    wp = profile["working_patterns"]
    if wp["peak_hours"]:
        lines.append("### ì‘ì—… íŒ¨í„´")
        lines.append(f"- ì£¼ìš” í™œë™ ì‹œê°„ëŒ€: {', '.join(f'{h}ì‹œ' for h in wp['peak_hours'])}")
        if wp["active_days"]:
            lines.append(f"- ì£¼ìš” í™œë™ ìš”ì¼: {', '.join(wp['active_days'])}")

    return "\n".join(lines)


def generate_visualizations(profile: dict, output_dir: Path) -> list[str]:
    """ì‹œê°í™” ì°¨íŠ¸ ìƒì„±"""
    if not HAS_MATPLOTLIB:
        print("matplotlibì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install matplotlib ì‹¤í–‰ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        return []

    # í•œê¸€ í°íŠ¸ ì„¤ì • (macOS)
    plt.rcParams['font.family'] = ['AppleGothic', 'Malgun Gothic', 'sans-serif']
    plt.rcParams['axes.unicode_minus'] = False

    output_dir.mkdir(parents=True, exist_ok=True)
    generated_files = []

    # 1. ì‘ì—… ìœ í˜• íŒŒì´ ì°¨íŠ¸
    if profile.get("task_types"):
        fig, ax = plt.subplots(figsize=(10, 8))
        task_types = profile["task_types"]
        labels = list(task_types.keys())
        sizes = list(task_types.values())
        colors = plt.cm.Pastel1(range(len(labels)))

        wedges, texts, autotexts = ax.pie(
            sizes, labels=labels, autopct='%1.1f%%',
            colors=colors, startangle=90
        )
        ax.set_title('ì‘ì—… ìœ í˜• ë¶„í¬', fontsize=16, fontweight='bold')

        filepath = output_dir / "task_types_pie.png"
        plt.savefig(filepath, dpi=150, bbox_inches='tight', facecolor='white')
        plt.close()
        generated_files.append(str(filepath))

    # 2. í™œë™ ì‹œê°„ëŒ€ ë°” ì°¨íŠ¸
    wp = profile.get("working_patterns", {})
    if "hours_detail" in profile:
        fig, ax = plt.subplots(figsize=(14, 6))
        hours_data = profile["hours_detail"]
        hours = list(range(24))
        counts = [hours_data.get(h, 0) for h in hours]

        bars = ax.bar(hours, counts, color='steelblue', edgecolor='navy', alpha=0.8)
        ax.set_xlabel('ì‹œê°„ (24ì‹œê°„)', fontsize=12)
        ax.set_ylabel('ì„¸ì…˜ ìˆ˜', fontsize=12)
        ax.set_title('ì‹œê°„ëŒ€ë³„ í™œë™ íŒ¨í„´', fontsize=16, fontweight='bold')
        ax.set_xticks(hours)
        ax.set_xticklabels([f'{h}ì‹œ' for h in hours], rotation=45, ha='right')
        ax.grid(axis='y', alpha=0.3)

        # í”¼í¬ ì‹œê°„ ê°•ì¡°
        peak_hours = wp.get("peak_hours", [])
        for i, bar in enumerate(bars):
            if i in peak_hours:
                bar.set_color('coral')
                bar.set_edgecolor('darkred')

        filepath = output_dir / "activity_hours.png"
        plt.savefig(filepath, dpi=150, bbox_inches='tight', facecolor='white')
        plt.close()
        generated_files.append(str(filepath))

    # 3. ê¸°ìˆ  ìŠ¤íƒ ë°” ì°¨íŠ¸
    if profile.get("tech_stack"):
        fig, axes = plt.subplots(2, 2, figsize=(14, 12))
        fig.suptitle('ê¸°ìˆ  ìŠ¤íƒ ë¶„ì„', fontsize=18, fontweight='bold')

        categories = ["languages", "frameworks", "tools", "databases"]
        titles = ["í”„ë¡œê·¸ë˜ë° ì–¸ì–´", "í”„ë ˆì„ì›Œí¬", "ë„êµ¬", "ë°ì´í„°ë² ì´ìŠ¤"]
        colors = ['#4CAF50', '#2196F3', '#FF9800', '#9C27B0']

        for idx, (cat, title, color) in enumerate(zip(categories, titles, colors)):
            ax = axes[idx // 2, idx % 2]
            data = profile["tech_stack"].get(cat, {})

            if data:
                techs = list(data.keys())[:8]
                counts = [data[t] for t in techs]

                bars = ax.barh(techs, counts, color=color, alpha=0.8, edgecolor='black')
                ax.set_xlabel('ì–¸ê¸‰ íšŸìˆ˜')
                ax.set_title(title, fontsize=14, fontweight='bold')
                ax.invert_yaxis()

                for bar, count in zip(bars, counts):
                    ax.text(bar.get_width() + 0.1, bar.get_y() + bar.get_height()/2,
                           str(count), va='center', fontsize=10)
            else:
                ax.text(0.5, 0.5, 'ë°ì´í„° ì—†ìŒ', ha='center', va='center', fontsize=12)
                ax.set_title(title, fontsize=14, fontweight='bold')

        plt.tight_layout()
        filepath = output_dir / "tech_stack.png"
        plt.savefig(filepath, dpi=150, bbox_inches='tight', facecolor='white')
        plt.close()
        generated_files.append(str(filepath))

    # 4. ìš”ì¼ë³„ í™œë™ ì°¨íŠ¸
    if "weekdays_detail" in profile:
        fig, ax = plt.subplots(figsize=(10, 6))
        weekdays_order = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
        weekdays_kr = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]
        weekdays_data = profile["weekdays_detail"]

        counts = [weekdays_data.get(d, 0) for d in weekdays_order]
        colors = ['#5DADE2'] * 5 + ['#F39C12'] * 2  # ì£¼ì¤‘ì€ íŒŒë‘, ì£¼ë§ì€ ì£¼í™©

        bars = ax.bar(weekdays_kr, counts, color=colors, edgecolor='black', alpha=0.8)
        ax.set_xlabel('ìš”ì¼', fontsize=12)
        ax.set_ylabel('ì„¸ì…˜ ìˆ˜', fontsize=12)
        ax.set_title('ìš”ì¼ë³„ í™œë™ íŒ¨í„´', fontsize=16, fontweight='bold')
        ax.grid(axis='y', alpha=0.3)

        for bar, count in zip(bars, counts):
            if count > 0:
                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.2,
                       str(count), ha='center', fontsize=11, fontweight='bold')

        filepath = output_dir / "activity_weekdays.png"
        plt.savefig(filepath, dpi=150, bbox_inches='tight', facecolor='white')
        plt.close()
        generated_files.append(str(filepath))

    # 5. ì¢…í•© ëŒ€ì‹œë³´ë“œ
    fig = plt.figure(figsize=(16, 12))
    fig.suptitle('ê°œë°œì í”„ë¡œí•„ ëŒ€ì‹œë³´ë“œ', fontsize=20, fontweight='bold', y=0.98)

    # ë©”íŠ¸ë¦­ ìš”ì•½
    ax1 = fig.add_subplot(2, 3, 1)
    ax1.axis('off')
    m = profile["metrics"]
    metrics_text = f"""
    ğŸ“Š í™œë™ í†µê³„

    ì´ ì„¸ì…˜: {m['total_sessions']}
    ì´ ë©”ì‹œì§€: {m['total_messages']}
    ì„¸ì…˜ë‹¹ ë©”ì‹œì§€: {m['avg_messages_per_session']:.1f}
    í‰ê·  ë©”ì‹œì§€ ê¸¸ì´: {m['avg_message_length']}ì
    ì§ˆë¬¸ ë¹„ìœ¨: {m['question_ratio']}%
    í”„ë¡œì íŠ¸ ìˆ˜: {profile['project_count']}
    """
    ax1.text(0.1, 0.5, metrics_text, fontsize=12, verticalalignment='center',
             fontfamily='monospace', bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.5))

    # ì‘ì—… ìœ í˜• (íŒŒì´)
    ax2 = fig.add_subplot(2, 3, 2)
    if profile.get("task_types"):
        task_types = profile["task_types"]
        ax2.pie(list(task_types.values()), labels=list(task_types.keys()),
               autopct='%1.0f%%', colors=plt.cm.Pastel1(range(len(task_types))))
    ax2.set_title('ì‘ì—… ìœ í˜•', fontsize=14, fontweight='bold')

    # ì£¼ìš” ì–¸ì–´ (ë°”)
    ax3 = fig.add_subplot(2, 3, 3)
    if profile.get("tech_stack", {}).get("languages"):
        langs = profile["tech_stack"]["languages"]
        ax3.barh(list(langs.keys())[:5], list(langs.values())[:5], color='#4CAF50')
        ax3.invert_yaxis()
    ax3.set_title('ì£¼ìš” ì–¸ì–´', fontsize=14, fontweight='bold')

    # ì‹œê°„ëŒ€ (ë°”)
    ax4 = fig.add_subplot(2, 3, 4)
    if "hours_detail" in profile:
        hours_data = profile["hours_detail"]
        hours = list(range(24))
        counts = [hours_data.get(h, 0) for h in hours]
        ax4.bar(hours, counts, color='steelblue', alpha=0.8)
        ax4.set_xticks([0, 6, 12, 18, 23])
        ax4.set_xticklabels(['0ì‹œ', '6ì‹œ', '12ì‹œ', '18ì‹œ', '23ì‹œ'])
    ax4.set_title('í™œë™ ì‹œê°„ëŒ€', fontsize=14, fontweight='bold')

    # ìš”ì¼ (ë°”)
    ax5 = fig.add_subplot(2, 3, 5)
    if "weekdays_detail" in profile:
        weekdays_order = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
        weekdays_kr = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]
        weekdays_data = profile["weekdays_detail"]
        counts = [weekdays_data.get(d, 0) for d in weekdays_order]
        colors = ['#5DADE2'] * 5 + ['#F39C12'] * 2
        ax5.bar(weekdays_kr, counts, color=colors)
    ax5.set_title('í™œë™ ìš”ì¼', fontsize=14, fontweight='bold')

    # ë„êµ¬ (ë°”)
    ax6 = fig.add_subplot(2, 3, 6)
    if profile.get("tech_stack", {}).get("tools"):
        tools = profile["tech_stack"]["tools"]
        ax6.barh(list(tools.keys())[:5], list(tools.values())[:5], color='#FF9800')
        ax6.invert_yaxis()
    ax6.set_title('ì£¼ìš” ë„êµ¬', fontsize=14, fontweight='bold')

    plt.tight_layout()
    filepath = output_dir / "dashboard.png"
    plt.savefig(filepath, dpi=150, bbox_inches='tight', facecolor='white')
    plt.close()
    generated_files.append(str(filepath))

    return generated_files


def main():
    import argparse

    parser = argparse.ArgumentParser(description="Claude Code ì‚¬ìš© ê¸°ë¡ ê¸°ë°˜ ê°œë°œì í”„ë¡œí•„ ë¶„ì„")
    parser.add_argument("--no-anonymize", action="store_true", help="ìµëª…í™”í•˜ì§€ ì•ŠìŒ")
    parser.add_argument("--json", action="store_true", help="JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥")
    parser.add_argument("--output", "-o", help="ì¶œë ¥ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--visualize", "-v", action="store_true", help="ì‹œê°í™” ì°¨íŠ¸ ìƒì„±")
    parser.add_argument("--viz-output", default="./profile_charts", help="ì‹œê°í™” ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: ./profile_charts)")
    args = parser.parse_args()

    profile = generate_profile(anonymize=not args.no_anonymize)

    # ì‹œê°í™” ìƒì„±
    if args.visualize:
        output_dir = Path(args.viz_output)
        generated = generate_visualizations(profile, output_dir)
        if generated:
            print(f"ì‹œê°í™” ìƒì„± ì™„ë£Œ:")
            for f in generated:
                print(f"  - {f}")
            print()

    if args.json:
        output = json.dumps(profile, indent=2, ensure_ascii=False)
    else:
        output = generate_summary(profile)

    if args.output:
        with open(args.output, "w") as f:
            f.write(output)
        print(f"ì €ì¥ë¨: {args.output}")
    else:
        print(output)


if __name__ == "__main__":
    main()
